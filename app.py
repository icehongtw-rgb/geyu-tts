import streamlit as st
import edge_tts
import asyncio
import zipfile
import io
import re
import shutil
import sys
from xml.sax.saxutils import escape

# --- 1. ç’°å¢ƒæª¢æ¸¬ (Pydub & FFmpeg) ---
HAS_FFMPEG = False
HAS_PYDUB = False
PYDUB_STATUS = "Checking..."

# æª¢æŸ¥ FFmpeg (ç³»çµ±å±¤ç´š)
if shutil.which("ffmpeg"):
    HAS_FFMPEG = True
else:
    HAS_FFMPEG = False

# æª¢æŸ¥ Pydub (Python å±¤ç´š)
try:
    from pydub import AudioSegment
    HAS_PYDUB = True
    PYDUB_STATUS = "Installed"
except ImportError:
    HAS_PYDUB = False
    PYDUB_STATUS = "Not Found"

# --- 2. è¨­å®šé é¢ ---
st.set_page_config(page_title="æ ¼è‚² - å…’ç«¥èªéŸ³åˆæˆå·¥å…·", page_icon="ğŸ§©", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; }
    .status-ok { background-color: #dcfce7; color: #166534; padding: 0.5rem; border-radius: 5px; margin-bottom: 10px; border: 1px solid #bbf7d0;}
    .status-err { background-color: #fee2e2; color: #991b1b; padding: 0.5rem; border-radius: 5px; margin-bottom: 10px; border: 1px solid #fecaca;}
    </style>
""", unsafe_allow_html=True)

# --- 3. èªéŸ³èˆ‡é¢¨æ ¼æ¸…å–® ---
VOICES = {
    "ç°¡é«”ä¸­æ–‡ (ä¸­åœ‹ - æ”¯æ´å¤šæƒ…æ„Ÿ)": {
        "zh-CN-XiaoxiaoNeural": "ğŸ‡¨ğŸ‡³ å°æ›‰ (å¥³è² - æ´»æ½‘/æ¨è–¦) ğŸ”¥",
        "zh-CN-YunxiNeural": "ğŸ‡¨ğŸ‡³ é›²å¸Œ (ç”·è² - å¸¥æ°£/å¤šæƒ…æ„Ÿ)",
        "zh-CN-XiaoyiNeural": "ğŸ‡¨ğŸ‡³ å°è— (å¥³è² - æ°£è³ª)",
        "zh-CN-YunjianNeural": "ğŸ‡¨ğŸ‡³ é›²å¥ (ç”·è² - é«”è‚²)",
        "zh-CN-XiaohanNeural": "ğŸ‡¨ğŸ‡³ æ›‰æ¶µ (å¥³è² - æº«æš–/è¬›æ•…äº‹)",
    },
    "ç¹é«”ä¸­æ–‡ (å°ç£)": {
        "zh-TW-HsiaoChenNeural": "ğŸ‡¹ğŸ‡¼ æ›‰è‡» (å¥³è² - æº«æŸ”/æ¨™æº–)",
        "zh-TW-YunJheNeural": "ğŸ‡¹ğŸ‡¼ é›²å“² (ç”·è² - æ²‰ç©©)",
        "zh-TW-HsiaoYuNeural": "ğŸ‡¹ğŸ‡¼ æ›‰é›¨ (å¥³è² - æ¸…æ™°)",
    },
    "è‹±æ–‡ (ç¾åœ‹)": {
        "en-US-AnaNeural": "ğŸ‡ºğŸ‡¸ Ana (å¥³è² - å…’ç«¥/å¯æ„›)",
        "en-US-AriaNeural": "ğŸ‡ºğŸ‡¸ Aria (å¥³è² - æ¨™æº–)",
        "en-US-GuyNeural": "ğŸ‡ºğŸ‡¸ Guy (ç”·è² - æ¨™æº–)",
    }
}

VOICES_WITH_STYLE = [
    "zh-CN-XiaoxiaoNeural", "zh-CN-YunxiNeural", "zh-CN-XiaoyiNeural", "zh-CN-XiaohanNeural",
    "en-US-AriaNeural", "en-US-GuyNeural", "en-US-AnaNeural"
]

STYLES = {
    "general": "é è¨­ (General)",
    "affectionate": "â¤ï¸ è¦ªåˆ‡/å“„å­©å­ (Affectionate)",
    "cheerful": "ğŸ˜„ é–‹å¿ƒ (Cheerful)",
    "gentle": "â˜ï¸ æº«å’Œ (Gentle)",
    "sad": "ğŸ˜¢ æ‚²å‚· (Sad)",
    "angry": "ğŸ˜¡ ç”Ÿæ°£ (Angry)",
    "whispering": "ğŸ¤« è€³èª (Whispering)",
    "shouting": "ğŸ“¢ å¤§å–Š (Shouting)",
}

# --- 4. å»é™¤éœéŸ³åŠŸèƒ½ ---
def trim_silence(audio_bytes):
    if not HAS_PYDUB or not HAS_FFMPEG:
        return audio_bytes 

    try:
        audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format="mp3")
        
        def detect_leading(sound, silence_threshold=-50.0, chunk_size=10):
            trim_ms = 0
            while trim_ms < len(sound) and sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold:
                trim_ms += chunk_size
            return trim_ms

        start_trim = detect_leading(audio)
        end_trim = detect_leading(audio.reverse())
        
        # åªè¦åˆ‡æ‰çš„é•·åº¦å°æ–¼ç¸½é•·åº¦ï¼Œå°±åŸ·è¡Œè£åˆ‡
        if start_trim + end_trim < len(audio):
            trimmed = audio[start_trim:len(audio)-end_trim]
            out = io.BytesIO()
            trimmed.export(out, format="mp3")
            return out.getvalue()
    except Exception:
        pass 
    
    return audio_bytes

# --- 5. æ ¸å¿ƒç”Ÿæˆé‚è¼¯ (é›™å¼•è™Ÿ SSML ä¿®å¾©ç‰ˆ) ---
async def generate_audio_stream(text, voice, rate, volume, pitch, style="general", remove_silence=False):
    # å¦‚æœé¸æ“‡äº†é¢¨æ ¼ï¼Œå¿…é ˆä½¿ç”¨ SSML
    if style != "general":
        escaped_text = escape(text)
        
        # ã€é—œéµä¿®å¾©ã€‘
        # 1. é€™è£¡å…¨éƒ¨ä½¿ç”¨é›™å¼•è™Ÿ " ä¾†åŒ…ä½å±¬æ€§
        # 2. ç§»é™¤äº† xml:lang é˜²æ­¢èˆ‡ voice è¡çª
        # 3. çµæ§‹ç·Šæ¹Šï¼Œæ²’æœ‰å¤šé¤˜æ›è¡Œ
        ssml = (
            f'<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="https://www.w3.org/2001/mstts">'
            f'<voice name="{voice}">'
            f'<mstts:express-as style="{style}">'
            f'<prosody rate="{rate}" volume="{volume}" pitch="{pitch}">'
            f'{escaped_text}'
            f'</prosody>'
            f'</mstts:express-as>'
            f'</voice>'
            f'</speak>'
        )
        communicate = edge_tts.Communicate(ssml, voice)
    else:
        # ä¸€èˆ¬æ¨¡å¼ (ç„¡ SSML)
        communicate = edge_tts.Communicate(text, voice, rate=rate, volume=volume, pitch=pitch)

    audio_data = io.BytesIO()
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data.write(chunk["data"])
    
    final_bytes = audio_data.getvalue()

    if remove_silence:
        final_bytes = trim_silence(final_bytes)
        
    return final_bytes

# --- 6. ä»‹é¢é‚è¼¯ ---
def main():
    with st.sidebar:
        st.title("âš™ï¸ åƒæ•¸è¨­å®š")
        st.caption("ç‰ˆæœ¬ï¼šv3.1 (Python 3.11 é©é…ç‰ˆ)")
        
        # ç’°å¢ƒè¨ºæ–·é¡¯ç¤º
        if HAS_PYDUB and HAS_FFMPEG:
            st.markdown('<div class="status-ok">âœ… ç’°å¢ƒå®Œæ•´ï¼šè‡ªå‹•å»éœéŸ³åŠŸèƒ½å·²å°±ç·’</div>', unsafe_allow_html=True)
        else:
            missing = []
            if not HAS_PYDUB: missing.append("Pydub (è«‹åœ¨ Streamlit è¨­å®šå°‡ Python æ”¹ç‚º 3.11)")
            if not HAS_FFMPEG: missing.append("FFmpeg (æª¢æŸ¥ packages.txt)")
            error_msg = "<br>".join(missing)
            st.markdown(f'<div class="status-err">âš ï¸ ç’°å¢ƒç¼ºå¤±ï¼š<br>{error_msg}</div>', unsafe_allow_html=True)

        st.subheader("1. èªéŸ³")
        category = st.selectbox("èªè¨€", list(VOICES.keys()))
        selected_voice = st.selectbox("è§’è‰²", list(VOICES[category].keys()), format_func=lambda x: VOICES[category][x])

        st.subheader("2. èª¿æ•´")
        rate = st.slider("èªé€Ÿ", -50, 100, 0, format="%d%%")
        pitch = st.slider("éŸ³èª¿", -50, 50, 0, format="%dHz")
        
        rate_str = f"{'+' if rate >= 0 else ''}{rate}%"
        pitch_str = f"{'+' if pitch >= 0 else ''}{pitch}Hz"
        vol_str = "+0%"

        st.subheader("3. é¢¨æ ¼")
        # æ™ºæ…§åˆ¤æ–·æ˜¯å¦é¡¯ç¤ºé¢¨æ ¼
        if selected_voice in VOICES_WITH_STYLE:
            style = st.selectbox("æƒ…æ„Ÿ", list(STYLES.keys()), format_func=lambda x: STYLES[x], index=1)
        else:
            style = "general"
            st.selectbox("æƒ…æ„Ÿ", ["é è¨­ (General)"], disabled=True, help="æ­¤è§’è‰²ä¸æ”¯æ´æƒ…æ„Ÿèª¿æ•´")
            if "zh-TW" in selected_voice:
                st.caption("â„¹ï¸ å°ç£èªéŸ³æš«ä¸æ”¯æ´æƒ…æ„Ÿï¼Œå»ºè­°èª¿æ•´èªé€Ÿèˆ‡éŸ³èª¿ä¾†æ¨¡æ“¬ã€‚")

        # è‡ªå‹•å‹¾é¸å»éœéŸ³ (å¦‚æœæ˜¯å¯ç”¨ç‹€æ…‹)
        remove_silence_opt = st.checkbox("âœ¨ è‡ªå‹•å»é™¤é ­å°¾éœéŸ³", value=True, disabled=not(HAS_PYDUB and HAS_FFMPEG))

    st.title("ğŸ§© æ ¼è‚² - å…’ç«¥èªéŸ³å·¥å…·")
    
    col1, col2 = st.columns([2, 1])
    with col1:
        text_input = st.text_area("è¼¸å…¥å…§å®¹ (ç·¨è™Ÿ å…§å®¹)", height=300, placeholder="001 è˜‹æœ\n002 é¦™è•‰")
    
    with col2:
        st.write("è©¦è½")
        test_txt = st.text_input("æ¸¬è©¦å¥", "å°æœ‹å‹å¥½ï¼")
        if st.button("ç”Ÿæˆè©¦è½"):
            with st.spinner("ç”Ÿæˆä¸­..."):
                try:
                    data = asyncio.run(generate_audio_stream(test_txt, selected_voice, rate_str, vol_str, pitch_str, style, remove_silence_opt))
                    st.audio(data, format='audio/mp3')
                except Exception as e:
                    st.error(f"éŒ¯èª¤: {e}")

    items = []
    for line in text_input.split('\n'):
        if line.strip():
            parts = line.strip().split(maxsplit=1)
            if len(parts) == 2:
                items.append((parts[0], parts[1]))
    
    if st.button(f"ğŸš€ æ‰¹é‡ç”Ÿæˆ ({len(items)} å€‹æª”æ¡ˆ)", type="primary", disabled=len(items)==0):
        zip_buf = io.BytesIO()
        prog = st.progress(0)
        
        with zipfile.ZipFile(zip_buf, "w") as zf:
            for i, (fname, txt) in enumerate(items):
                try:
                    data = asyncio.run(generate_audio_stream(txt, selected_voice, rate_str, vol_str, pitch_str, style, remove_silence_opt))
                    zf.writestr(f"{fname}.mp3", data)
                except Exception as e:
                    st.error(f"{fname} å¤±æ•—: {e}")
                prog.progress((i+1)/len(items))
        
        st.success("å®Œæˆï¼")
        st.download_button("ğŸ“¥ ä¸‹è¼‰ ZIP", zip_buf.getvalue(), "audio.zip", "application/zip")

if __name__ == "__main__":
    main()