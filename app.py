import streamlit as st
import edge_tts
import asyncio
import zipfile
import io
import re
import shutil
import sys
from xml.sax.saxutils import escape

# --- 1. ç’°å¢ƒæª¢æ¸¬ ---
HAS_FFMPEG = False
HAS_PYDUB = False

if shutil.which("ffmpeg"):
    HAS_FFMPEG = True

try:
    from pydub import AudioSegment
    HAS_PYDUB = True
except ImportError:
    HAS_PYDUB = False

# --- 2. è¨­å®šé é¢ ---
st.set_page_config(page_title="æ ¼è‚² - å…’ç«¥èªéŸ³å·¥å…·", page_icon="ğŸ§©", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; }
    .status-ok { background-color: #dcfce7; color: #166534; padding: 0.5rem; border-radius: 5px; margin-bottom: 10px; border: 1px solid #bbf7d0;}
    .status-err { background-color: #fee2e2; color: #991b1b; padding: 0.5rem; border-radius: 5px; margin-bottom: 10px; border: 1px solid #fecaca;}
    .debug-box { font-family: monospace; font-size: 0.8rem; background: #e2e8f0; padding: 5px; border-radius: 3px; margin-top: 5px; }
    </style>
""", unsafe_allow_html=True)

# --- 3. èªéŸ³æ¸…å–® ---
VOICES = {
    "ç°¡é«”ä¸­æ–‡ (ä¸­åœ‹)": {
        "zh-CN-XiaoxiaoNeural": "ğŸ‡¨ğŸ‡³ å°æ›‰ (å¥³è² - æ´»æ½‘/æ¨è–¦) ğŸ”¥",
        "zh-CN-YunxiNeural": "ğŸ‡¨ğŸ‡³ é›²å¸Œ (ç”·è² - å¸¥æ°£)",
        "zh-CN-XiaoyiNeural": "ğŸ‡¨ğŸ‡³ å°è— (å¥³è² - æ°£è³ª)",
        "zh-CN-YunjianNeural": "ğŸ‡¨ğŸ‡³ é›²å¥ (ç”·è² - é«”è‚²)",
        "zh-CN-XiaohanNeural": "ğŸ‡¨ğŸ‡³ æ›‰æ¶µ (å¥³è² - æº«æš–)",
    },
    "ç¹é«”ä¸­æ–‡ (å°ç£)": {
        "zh-TW-HsiaoChenNeural": "ğŸ‡¹ğŸ‡¼ æ›‰è‡» (å¥³è² - æº«æŸ”/æ¨™æº–)",
        "zh-TW-YunJheNeural": "ğŸ‡¹ğŸ‡¼ é›²å“² (ç”·è² - æ²‰ç©©)",
        "zh-TW-HsiaoYuNeural": "ğŸ‡¹ğŸ‡¼ æ›‰é›¨ (å¥³è² - æ¸…æ™°)",
    },
    "è‹±æ–‡ (ç¾åœ‹)": {
        "en-US-AnaNeural": "ğŸ‡ºğŸ‡¸ Ana (å¥³è² - å…’ç«¥/å¯æ„›)",
        "en-US-AriaNeural": "ğŸ‡ºğŸ‡¸ Aria (å¥³è² - æ¨™æº–)",
        "en-US-GuyNeural": "ğŸ‡ºğŸ‡¸ Guy (ç”·è² - æ¨™æº–)",
    }
}

# --- 4. é¢¨æ ¼æ¨¡æ“¬åƒæ•¸ (ç‰©ç†å¤–æ›) ---
# é€™è£¡å®šç¾©äº†æ¯å€‹é¢¨æ ¼å°æ‡‰çš„ã€Œèªé€Ÿã€å’Œã€ŒéŸ³èª¿ã€åç§»é‡
# é€™ç¨®æ–¹å¼ 100% å®‰å…¨ï¼Œå› ç‚ºå®ƒåªä½¿ç”¨äº†åŸºç¤çš„ prosody æ¨™ç±¤
STYLE_PARAMS = {
    "general":      {"rate": 0,   "pitch": 0},
    "affectionate": {"rate": -15, "pitch": -2}, # å“„å­©å­ï¼šæ…¢ä¸€é»ï¼Œä½æ²‰æº«æŸ”
    "cheerful":     {"rate": 10,  "pitch": 3},  # é–‹å¿ƒï¼šå¿«ä¸€é»ï¼Œé«˜äº¢
    "gentle":       {"rate": -10, "pitch": 0},  # æº«å’Œï¼šç¨æ…¢ï¼Œå¹³ç©©
    "sad":          {"rate": -15, "pitch": -5}, # æ‚²å‚·ï¼šå¾ˆæ…¢ï¼Œä½æ²‰
    "angry":        {"rate": 5,   "pitch": 5},  # ç”Ÿæ°£ï¼šç¨å¿«ï¼Œé«˜äº¢
    "whispering":   {"rate": -20, "pitch": -5}, # è€³èªï¼šéå¸¸æ…¢
    "shouting":     {"rate": 5,   "pitch": 8},  # å¤§å–Šï¼šé«˜éŸ³
}

STYLES = {
    "general": "é è¨­ (General)",
    "affectionate": "â¤ï¸ è¦ªåˆ‡/å“„å­©å­ (æ¨¡æ“¬)",
    "cheerful": "ğŸ˜„ é–‹å¿ƒ (æ¨¡æ“¬)",
    "gentle": "â˜ï¸ æº«å’Œ (æ¨¡æ“¬)",
    "sad": "ğŸ˜¢ æ‚²å‚· (æ¨¡æ“¬)",
    "angry": "ğŸ˜¡ ç”Ÿæ°£ (æ¨¡æ“¬)",
    "whispering": "ğŸ¤« è€³èª (æ¨¡æ“¬)",
    "shouting": "ğŸ“¢ å¤§å–Š (æ¨¡æ“¬)",
}

# --- 5. è¼”åŠ©åŠŸèƒ½ ---
def trim_silence(audio_bytes):
    if not HAS_PYDUB or not HAS_FFMPEG: return audio_bytes 
    try:
        audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format="mp3")
        def detect_leading(sound, silence_threshold=-50.0, chunk_size=10):
            trim_ms = 0
            while trim_ms < len(sound) and sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold:
                trim_ms += chunk_size
            return trim_ms
        start_trim = detect_leading(audio)
        end_trim = detect_leading(audio.reverse())
        if start_trim + end_trim < len(audio):
            trimmed = audio[start_trim:len(audio)-end_trim]
            out = io.BytesIO()
            trimmed.export(out, format="mp3")
            return out.getvalue()
    except: pass 
    return audio_bytes

# --- 6. æ ¸å¿ƒç”Ÿæˆé‚è¼¯ (v16.0: ç‰©ç†æ¨¡æ“¬ç‰ˆ) ---
async def generate_audio_stream(text, voice, user_rate, user_volume, user_pitch, style="general", remove_silence=False):
    # 1. å–å¾—é¢¨æ ¼å°æ‡‰çš„ç‰©ç†åƒæ•¸
    style_settings = STYLE_PARAMS.get(style, STYLE_PARAMS["general"])
    
    # 2. å°‡ã€Œä½¿ç”¨è€…è¨­å®šã€èˆ‡ã€Œé¢¨æ ¼é è¨­ã€ç›¸åŠ 
    # ä¾‹å¦‚ï¼šä½¿ç”¨è€…è¨­ +0%ï¼Œé¢¨æ ¼æ˜¯ -15%ï¼Œçµæœå°±æ˜¯ -15%
    final_rate_val = user_rate + style_settings["rate"]
    final_pitch_val = user_pitch + style_settings["pitch"]
    
    # 3. è½‰æˆå­—ä¸²æ ¼å¼
    rate_str = f"{'+' if final_rate_val >= 0 else ''}{final_rate_val}%"
    pitch_str = f"{'+' if final_pitch_val >= 0 else ''}{final_pitch_val}Hz"
    volume_str = f"{'+' if user_volume >= 0 else ''}{user_volume}%"
    
    # 4. æ§‹å»ºæœ€ç°¡å–®ã€æœ€ç©©å®šçš„ SSML (åªç”¨ voice å’Œ prosody)
    # é€™è£¡å®Œå…¨æ£„ç”¨äº† mstts:express-asï¼Œæ‰€ä»¥çµ•å°ä¸æœƒæœ‰ç›¸å®¹æ€§å•é¡Œ
    escaped_text = escape(text)
    
    ssml_parts = [
        '<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xml:lang="zh-CN">',
        f'<voice name="{voice}">',
        f'<prosody rate="{rate_str}" volume="{volume_str}" pitch="{pitch_str}">',
        escaped_text,
        '</prosody>',
        '</voice>',
        '</speak>'
    ]
    
    clean_ssml = "".join(ssml_parts)
    
    # å‚³é€çµ¦ edge-tts
    communicate = edge_tts.Communicate(clean_ssml, voice)
    
    # é€™è£¡å¯ä»¥ä¿ç•™ï¼Œç¢ºä¿è¬ç„¡ä¸€å¤±
    if hasattr(communicate, "_ssml"): communicate._ssml = True
    if hasattr(communicate, "_text"): communicate._text = clean_ssml

    audio_data = io.BytesIO()
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data.write(chunk["data"])
    
    final_bytes = audio_data.getvalue()
    
    # Debug info
    debug_info = {
        "style_applied": style,
        "final_rate": rate_str,
        "final_pitch": pitch_str,
        "raw_ssml": clean_ssml
    }

    if remove_silence:
        final_bytes = trim_silence(final_bytes)
        
    return final_bytes, debug_info

# --- 7. ä»‹é¢é‚è¼¯ ---
def main():
    with st.sidebar:
        st.title("âš™ï¸ åƒæ•¸è¨­å®š")
        st.caption("ç‰ˆæœ¬ï¼šv16.0 (ç‰©ç†æ¨¡æ“¬ç‰ˆ)")
        
        if HAS_PYDUB and HAS_FFMPEG:
            st.markdown('<div class="status-ok">âœ… ç’°å¢ƒå®Œæ•´</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="status-err">âš ï¸ ç’°å¢ƒç¼ºå¤± (éœ€ Python 3.11)</div>', unsafe_allow_html=True)

        st.subheader("1. èªéŸ³")
        category = st.selectbox("èªè¨€", list(VOICES.keys()))
        selected_voice = st.selectbox("è§’è‰²", list(VOICES[category].keys()), format_func=lambda x: VOICES[category][x])

        st.subheader("2. èª¿æ•´ (åŸºç¤)")
        # é€™è£¡çš„æ•¸å€¼æœƒèˆ‡é¢¨æ ¼ç–ŠåŠ 
        rate = st.slider("èªé€Ÿå¾®èª¿", -50, 50, 0, format="%d%%", help="æ­¤æ•¸å€¼æœƒç–ŠåŠ åœ¨é¢¨æ ¼é è¨­å€¼ä¸Š")
        pitch = st.slider("éŸ³èª¿å¾®èª¿", -50, 50, 0, format="%dHz", help="æ­¤æ•¸å€¼æœƒç–ŠåŠ åœ¨é¢¨æ ¼é è¨­å€¼ä¸Š")
        volume = st.slider("éŸ³é‡", -50, 50, 0, format="%d%%")

        st.subheader("3. é¢¨æ ¼ (æ¨¡æ“¬)")
        style = st.selectbox("æƒ…æ„Ÿé è¨­", list(STYLES.keys()), format_func=lambda x: STYLES[x], index=0)
        
        if style != "general":
            p = STYLE_PARAMS[style]
            st.info(f"ğŸ’¡ ç›®å‰é¢¨æ ¼è¨­å®šï¼šèªé€Ÿ {p['rate']}%, éŸ³èª¿ {p['pitch']}Hz")

        remove_silence_opt = st.checkbox("âœ¨ è‡ªå‹•å»éœéŸ³", value=True, disabled=not(HAS_PYDUB and HAS_FFMPEG))
        show_debug = st.checkbox("ğŸ” é¡¯ç¤ºåƒæ•¸è©³æƒ…", value=False)

    st.title("ğŸ§© æ ¼è‚² - å…’ç«¥èªéŸ³å·¥å…·")
    
    col1, col2 = st.columns([2, 1])
    with col1:
        text_input = st.text_area("è¼¸å…¥å…§å®¹", height=300, placeholder="001 è˜‹æœ\n002 é¦™è•‰")
    
    with col2:
        st.write("è©¦è½å€")
        test_txt = st.text_input("æ¸¬è©¦å¥", "å°æœ‹å‹å¥½ï¼")
        if st.button("ç”Ÿæˆè©¦è½"):
            with st.spinner("ç”Ÿæˆä¸­..."):
                try:
                    data, dbg = asyncio.run(generate_audio_stream(test_txt, selected_voice, rate, volume, pitch, style, remove_silence_opt))
                    st.audio(data, format='audio/mp3')
                    if show_debug:
                         st.write(f"æœ€çµ‚åƒæ•¸: Rate={dbg['final_rate']}, Pitch={dbg['final_pitch']}")
                         st.code(dbg["raw_ssml"], language="xml")
                except Exception as e:
                    st.error(f"éŒ¯èª¤: {e}")

    items = []
    for line in text_input.split('\n'):
        if line.strip():
            parts = line.strip().split(maxsplit=1)
            if len(parts) == 2:
                items.append((parts[0], parts[1]))
    
    if st.button(f"ğŸš€ æ‰¹é‡ç”Ÿæˆ ({len(items)} å€‹æª”æ¡ˆ)", type="primary", disabled=len(items)==0):
        zip_buffer = io.BytesIO()
        prog = st.progress(0)
        
        with zipfile.ZipFile(zip_buffer, "w") as zf:
            for i, (fname, txt) in enumerate(items):
                try:
                    data, dbg = asyncio.run(generate_audio_stream(txt, selected_voice, rate, volume, pitch, style, remove_silence_opt))
                    zf.writestr(f"{fname}.mp3", data)
                except Exception as e:
                    st.error(f"{fname} å¤±æ•—: {e}")
                prog.progress((i+1)/len(items))
        st.success("å®Œæˆï¼")
        st.download_button("ğŸ“¥ ä¸‹è¼‰ ZIP", zip_buffer.getvalue(), "audio.zip", "application/zip")

if __name__ == "__main__":
    main()