import streamlit as st
import edge_tts
import asyncio
import zipfile
import io
import re
import shutil
import sys
from xml.sax.saxutils import escape

# --- 1. ç’°å¢ƒæª¢æ¸¬ (Pydub & FFmpeg) ---
HAS_FFMPEG = False
HAS_PYDUB = False
PYDUB_STATUS = "Checking..."

# æª¢æŸ¥ FFmpeg
if shutil.which("ffmpeg"):
    HAS_FFMPEG = True

# æª¢æŸ¥ Pydub
try:
    from pydub import AudioSegment
    HAS_PYDUB = True
    PYDUB_STATUS = "Installed"
except ImportError:
    HAS_PYDUB = False
    PYDUB_STATUS = "Not Found"

# --- 2. è¨­å®šé é¢ ---
st.set_page_config(page_title="æ ¼è‚² - å…’ç«¥èªéŸ³åˆæˆå·¥å…·", page_icon="ğŸ§©", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; }
    .status-ok { background-color: #dcfce7; color: #166534; padding: 0.5rem; border-radius: 5px; margin-bottom: 10px; border: 1px solid #bbf7d0;}
    .status-err { background-color: #fee2e2; color: #991b1b; padding: 0.5rem; border-radius: 5px; margin-bottom: 10px; border: 1px solid #fecaca;}
    </style>
""", unsafe_allow_html=True)

# --- 3. èªéŸ³èˆ‡é¢¨æ ¼æ¸…å–® ---
VOICES = {
    "ç°¡é«”ä¸­æ–‡ (ä¸­åœ‹ - æ”¯æ´å¤šæƒ…æ„Ÿ)": {
        "zh-CN-XiaoxiaoNeural": "ğŸ‡¨ğŸ‡³ å°æ›‰ (å¥³è² - æ´»æ½‘/æ¨è–¦) ğŸ”¥",
        "zh-CN-YunxiNeural": "ğŸ‡¨ğŸ‡³ é›²å¸Œ (ç”·è² - å¸¥æ°£/å¤šæƒ…æ„Ÿ)",
        "zh-CN-XiaoyiNeural": "ğŸ‡¨ğŸ‡³ å°è— (å¥³è² - æ°£è³ª)",
        "zh-CN-YunjianNeural": "ğŸ‡¨ğŸ‡³ é›²å¥ (ç”·è² - é«”è‚²)",
        "zh-CN-XiaohanNeural": "ğŸ‡¨ğŸ‡³ æ›‰æ¶µ (å¥³è² - æº«æš–/è¬›æ•…äº‹)",
    },
    "ç¹é«”ä¸­æ–‡ (å°ç£)": {
        "zh-TW-HsiaoChenNeural": "ğŸ‡¹ğŸ‡¼ æ›‰è‡» (å¥³è² - æº«æŸ”/æ¨™æº–)",
        "zh-TW-YunJheNeural": "ğŸ‡¹ğŸ‡¼ é›²å“² (ç”·è² - æ²‰ç©©)",
        "zh-TW-HsiaoYuNeural": "ğŸ‡¹ğŸ‡¼ æ›‰é›¨ (å¥³è² - æ¸…æ™°)",
    },
    "è‹±æ–‡ (ç¾åœ‹)": {
        "en-US-AnaNeural": "ğŸ‡ºğŸ‡¸ Ana (å¥³è² - å…’ç«¥/å¯æ„›)",
        "en-US-AriaNeural": "ğŸ‡ºğŸ‡¸ Aria (å¥³è² - æ¨™æº–)",
        "en-US-GuyNeural": "ğŸ‡ºğŸ‡¸ Guy (ç”·è² - æ¨™æº–)",
    }
}

VOICES_WITH_STYLE = [
    "zh-CN-XiaoxiaoNeural", "zh-CN-YunxiNeural", "zh-CN-XiaoyiNeural", "zh-CN-XiaohanNeural",
    "en-US-AriaNeural", "en-US-GuyNeural", "en-US-AnaNeural"
]

STYLES = {
    "general": "é è¨­ (General)",
    "affectionate": "â¤ï¸ è¦ªåˆ‡/å“„å­©å­ (Affectionate)",
    "cheerful": "ğŸ˜„ é–‹å¿ƒ (Cheerful)",
    "gentle": "â˜ï¸ æº«å’Œ (Gentle)",
    "sad": "ğŸ˜¢ æ‚²å‚· (Sad)",
    "angry": "ğŸ˜¡ ç”Ÿæ°£ (Angry)",
    "whispering": "ğŸ¤« è€³èª (Whispering)",
    "shouting": "ğŸ“¢ å¤§å–Š (Shouting)",
}

# --- 4. å»é™¤éœéŸ³åŠŸèƒ½ ---
def trim_silence(audio_bytes):
    if not HAS_PYDUB or not HAS_FFMPEG:
        return audio_bytes 

    try:
        audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format="mp3")
        
        def detect_leading(sound, silence_threshold=-50.0, chunk_size=10):
            trim_ms = 0
            while trim_ms < len(sound) and sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold:
                trim_ms += chunk_size
            return trim_ms

        start_trim = detect_leading(audio)
        end_trim = detect_leading(audio.reverse())
        
        if start_trim + end_trim < len(audio):
            trimmed = audio[start_trim:len(audio)-end_trim]
            out = io.BytesIO()
            trimmed.export(out, format="mp3")
            return out.getvalue()
    except Exception:
        pass 
    
    return audio_bytes

# --- 5. æ ¸å¿ƒç”Ÿæˆé‚è¼¯ (v5.0: çµ•å°ç´”æ·¨ç‰ˆ) ---
async def generate_audio_stream(text, voice, rate, volume, pitch, style="general", remove_silence=False):
    debug_ssml = None
    
    # å¦‚æœé¸æ“‡äº†é¢¨æ ¼ï¼Œå¿…é ˆä½¿ç”¨ SSML
    if style != "general":
        escaped_text = escape(text)
        
        # æå–èªè¨€ä»£ç¢¼
        lang_code = "zh-CN"
        if "zh-TW" in voice: lang_code = "zh-TW"
        if "en-US" in voice: lang_code = "en-US"

        # ã€v5.0 é—œéµä¿®å¾©ã€‘: æ”¾æ£„å¤šè¡Œå­—ä¸²ï¼Œæ”¹ç”¨åˆ—è¡¨æ‹¼æ¥
        # é€™èƒ½ 100% é¿å…éš±å½¢å­—ç¬¦å°è‡´ edge-tts åˆ¤æ–·å¤±æ•ˆ
        parts = []
        parts.append(f'<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="{lang_code}">')
        parts.append(f'<voice name="{voice}">')
        parts.append(f'<mstts:express-as style="{style}">')
        parts.append(f'<prosody rate="{rate}" volume="{volume}" pitch="{pitch}">')
        parts.append(f'{escaped_text}')
        parts.append('</prosody>')
        parts.append('</mstts:express-as>')
        parts.append('</voice>')
        parts.append('</speak>')
        
        # ç›´æ¥åˆä½µï¼Œä¸­é–“ä¸åŠ ä»»ä½•æ±è¥¿
        clean_ssml = "".join(parts)
        debug_ssml = clean_ssml 
        
        # å‚³é€çµ¦ edge-tts (å› ç‚ºå­—ä¸²ç¢ºå¯¦ä»¥ <speak é–‹é ­ï¼Œåº«æœƒè­˜åˆ¥ç‚º SSML)
        communicate = edge_tts.Communicate(clean_ssml, voice)
    else:
        # ä¸€èˆ¬æ¨¡å¼
        communicate = edge_tts.Communicate(text, voice, rate=rate, volume=volume, pitch=pitch)

    audio_data = io.BytesIO()
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data.write(chunk["data"])
    
    final_bytes = audio_data.getvalue()

    if remove_silence:
        final_bytes = trim_silence(final_bytes)
        
    return final_bytes, debug_ssml

# --- 6. ä»‹é¢é‚è¼¯ ---
def main():
    with st.sidebar:
        st.title("âš™ï¸ åƒæ•¸è¨­å®š")
        st.caption("ç‰ˆæœ¬ï¼šv5.0 (ç´”æ·¨æ‹¼æ¥ç‰ˆ)")
        
        # ç’°å¢ƒè¨ºæ–·
        if HAS_PYDUB and HAS_FFMPEG:
            st.markdown('<div class="status-ok">âœ… ç’°å¢ƒå®Œæ•´ï¼šè‡ªå‹•å»éœéŸ³åŠŸèƒ½å·²å°±ç·’</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="status-err">âš ï¸ ç’°å¢ƒç¼ºå¤±ï¼šè«‹ç¢ºèª Python ç‰ˆæœ¬ç‚º 3.11</div>', unsafe_allow_html=True)

        st.subheader("1. èªéŸ³")
        category = st.selectbox("èªè¨€", list(VOICES.keys()))
        selected_voice = st.selectbox("è§’è‰²", list(VOICES[category].keys()), format_func=lambda x: VOICES[category][x])

        st.subheader("2. èª¿æ•´")
        rate = st.slider("èªé€Ÿ", -50, 100, 0, format="%d%%")
        pitch = st.slider("éŸ³èª¿", -50, 50, 0, format="%dHz")
        
        rate_str = f"{'+' if rate >= 0 else ''}{rate}%"
        pitch_str = f"{'+' if pitch >= 0 else ''}{pitch}Hz"
        vol_str = "+0%"

        st.subheader("3. é¢¨æ ¼")
        if selected_voice in VOICES_WITH_STYLE:
            style = st.selectbox("æƒ…æ„Ÿ", list(STYLES.keys()), format_func=lambda x: STYLES[x], index=1)
        else:
            style = "general"
            st.selectbox("æƒ…æ„Ÿ", ["é è¨­ (General)"], disabled=True)
            if "zh-TW" in selected_voice:
                st.caption("â„¹ï¸ å°ç£èªéŸ³æš«ä¸æ”¯æ´æƒ…æ„Ÿ")

        remove_silence_opt = st.checkbox("âœ¨ è‡ªå‹•å»é™¤é ­å°¾éœéŸ³", value=True, disabled=not(HAS_PYDUB and HAS_FFMPEG))
        show_debug = st.checkbox("ğŸ é¡¯ç¤º SSML (è‹¥ç™¼éŸ³ç•°å¸¸è«‹å‹¾é¸)", value=False)

    st.title("ğŸ§© æ ¼è‚² - å…’ç«¥èªéŸ³å·¥å…·")
    
    col1, col2 = st.columns([2, 1])
    with col1:
        text_input = st.text_area("è¼¸å…¥å…§å®¹ (ç·¨è™Ÿ å…§å®¹)", height=300, placeholder="001 è˜‹æœ\n002 é¦™è•‰")
    
    with col2:
        st.write("è©¦è½")
        test_txt = st.text_input("æ¸¬è©¦å¥", "å°æœ‹å‹å¥½ï¼")
        if st.button("ç”Ÿæˆè©¦è½"):
            with st.spinner("ç”Ÿæˆä¸­..."):
                try:
                    data, dbg = asyncio.run(generate_audio_stream(test_txt, selected_voice, rate_str, vol_str, pitch_str, style, remove_silence_opt))
                    st.audio(data, format='audio/mp3')
                    if show_debug and dbg:
                        st.text_area("Debug SSML", dbg)
                except Exception as e:
                    st.error(f"éŒ¯èª¤: {e}")

    items = []
    for line in text_input.split('\n'):
        if line.strip():
            parts = line.strip().split(maxsplit=1)
            if len(parts) == 2:
                items.append((parts[0], parts[1]))
    
    if st.button(f"ğŸš€ æ‰¹é‡ç”Ÿæˆ ({len(items)} å€‹æª”æ¡ˆ)", type="primary", disabled=len(items)==0):
        zip_buf = io.BytesIO()
        prog = st.progress(0)
        
        with zipfile.ZipFile(zip_buf, "w") as zf:
            for i, (fname, txt) in enumerate(items):
                try:
                    data, dbg = asyncio.run(generate_audio_stream(txt, selected_voice, rate_str, vol_str, pitch_str, style, remove_silence_opt))
                    zf.writestr(f"{fname}.mp3", data)
                except Exception as e:
                    st.error(f"{fname} å¤±æ•—: {e}")
                prog.progress((i+1)/len(items))
        
        st.success("å®Œæˆï¼")
        st.download_button("ğŸ“¥ ä¸‹è¼‰ ZIP", zip_buf.getvalue(), "audio.zip", "application/zip")

if __name__ == "__main__":
    main()