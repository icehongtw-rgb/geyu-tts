import streamlit as st
import edge_tts
import asyncio
import zipfile
import io
import re
import shutil
import sys
from xml.sax.saxutils import escape

# --- 1. ç’°å¢ƒæª¢æ¸¬ ---
HAS_FFMPEG = False
HAS_PYDUB = False

# æª¢æŸ¥ FFmpeg
if shutil.which("ffmpeg"):
    HAS_FFMPEG = True

# æª¢æŸ¥ Pydub
try:
    from pydub import AudioSegment
    HAS_PYDUB = True
except ImportError:
    HAS_PYDUB = False

# --- 2. è¨­å®šé é¢ ---
st.set_page_config(page_title="æ ¼è‚² - å…’ç«¥èªéŸ³å·¥å…·", page_icon="ğŸ§©", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #f8fafc; }
    .status-ok { background-color: #dcfce7; color: #166534; padding: 0.5rem; border-radius: 5px; margin-bottom: 10px; border: 1px solid #bbf7d0;}
    .status-err { background-color: #fee2e2; color: #991b1b; padding: 0.5rem; border-radius: 5px; margin-bottom: 10px; border: 1px solid #fecaca;}
    .debug-box { font-family: monospace; font-size: 0.8rem; background: #e2e8f0; padding: 5px; border-radius: 3px; margin-top: 5px; }
    </style>
""", unsafe_allow_html=True)

# --- 3. èªéŸ³æ¸…å–® ---
VOICES = {
    "ç°¡é«”ä¸­æ–‡ (ä¸­åœ‹ - æ”¯æ´å¤šæƒ…æ„Ÿ)": {
        "zh-CN-XiaoxiaoNeural": "ğŸ‡¨ğŸ‡³ å°æ›‰ (å¥³è² - æ´»æ½‘/æ¨è–¦) ğŸ”¥",
        "zh-CN-YunxiNeural": "ğŸ‡¨ğŸ‡³ é›²å¸Œ (ç”·è² - å¸¥æ°£/å¤šæƒ…æ„Ÿ)",
        "zh-CN-XiaoyiNeural": "ğŸ‡¨ğŸ‡³ å°è— (å¥³è² - æ°£è³ª)",
        "zh-CN-YunjianNeural": "ğŸ‡¨ğŸ‡³ é›²å¥ (ç”·è² - é«”è‚²)",
        "zh-CN-XiaohanNeural": "ğŸ‡¨ğŸ‡³ æ›‰æ¶µ (å¥³è² - æº«æš–/è¬›æ•…äº‹)",
    },
    "ç¹é«”ä¸­æ–‡ (å°ç£)": {
        "zh-TW-HsiaoChenNeural": "ğŸ‡¹ğŸ‡¼ æ›‰è‡» (å¥³è² - æº«æŸ”/æ¨™æº–)",
        "zh-TW-YunJheNeural": "ğŸ‡¹ğŸ‡¼ é›²å“² (ç”·è² - æ²‰ç©©)",
        "zh-TW-HsiaoYuNeural": "ğŸ‡¹ğŸ‡¼ æ›‰é›¨ (å¥³è² - æ¸…æ™°)",
    },
    "è‹±æ–‡ (ç¾åœ‹)": {
        "en-US-AnaNeural": "ğŸ‡ºğŸ‡¸ Ana (å¥³è² - å…’ç«¥/å¯æ„›)",
        "en-US-AriaNeural": "ğŸ‡ºğŸ‡¸ Aria (å¥³è² - æ¨™æº–)",
        "en-US-GuyNeural": "ğŸ‡ºğŸ‡¸ Guy (ç”·è² - æ¨™æº–)",
    }
}

VOICES_WITH_STYLE = [
    "zh-CN-XiaoxiaoNeural", "zh-CN-YunxiNeural", "zh-CN-XiaoyiNeural", "zh-CN-XiaohanNeural",
    "en-US-AriaNeural", "en-US-GuyNeural", "en-US-AnaNeural"
]

STYLES = {
    "general": "é è¨­ (General)",
    "affectionate": "â¤ï¸ è¦ªåˆ‡/å“„å­©å­ (Affectionate)",
    "cheerful": "ğŸ˜„ é–‹å¿ƒ (Cheerful)",
    "gentle": "â˜ï¸ æº«å’Œ (Gentle)",
    "sad": "ğŸ˜¢ æ‚²å‚· (Sad)",
    "angry": "ğŸ˜¡ ç”Ÿæ°£ (Angry)",
    "whispering": "ğŸ¤« è€³èª (Whispering)",
    "shouting": "ğŸ“¢ å¤§å–Š (Shouting)",
}

# --- 4. è¼”åŠ©åŠŸèƒ½ ---
def trim_silence(audio_bytes):
    if not HAS_PYDUB or not HAS_FFMPEG: return audio_bytes 
    try:
        audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format="mp3")
        def detect_leading(sound, silence_threshold=-50.0, chunk_size=10):
            trim_ms = 0
            while trim_ms < len(sound) and sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold:
                trim_ms += chunk_size
            return trim_ms
        start_trim = detect_leading(audio)
        end_trim = detect_leading(audio.reverse())
        if start_trim + end_trim < len(audio):
            trimmed = audio[start_trim:len(audio)-end_trim]
            out = io.BytesIO()
            trimmed.export(out, format="mp3")
            return out.getvalue()
    except: pass 
    return audio_bytes

# --- 5. æ ¸å¿ƒç”Ÿæˆé‚è¼¯ (v10.1: ä¿®å¾©èªæ³•éŒ¯èª¤) ---
async def generate_audio_stream(text, voice, rate, volume, pitch, style="general", remove_silence=False):
    debug_info = {"is_ssml": False, "raw_ssml": ""}
    
    # ç­–ç•¥ 1: ä¸€èˆ¬æ¨¡å¼
    if style == "general":
        communicate = edge_tts.Communicate(text, voice, rate=rate, volume=volume, pitch=pitch)
    
    # ç­–ç•¥ 2: é¢¨æ ¼æ¨¡å¼ (æ¨™æº– SSML æ§‹å»º)
    else:
        escaped_text = escape(text)
        
        # åˆ¤æ–·æ˜¯å¦éœ€è¦ Prosody
        has_prosody = not (rate == "+0%" and volume == "+0%" and pitch == "+0Hz")
        
        # v10.1: ä½¿ç”¨ zh-CN ä¸¦ç¢ºä¿é›™å¼•è™Ÿ
        ssml_parts = [
            '<speak version="1.0" xmlns="http://www.w3.org/2001/10/synthesis" xmlns:mstts="https://www.w3.org/2001/mstts" xml:lang="zh-CN">',
            f'<voice name="{voice}">',
            f'<mstts:express-as style="{style}">',
        ]
        
        if has_prosody:
            ssml_parts.append(f'<prosody rate="{rate}" volume="{volume}" pitch="{pitch}">')
            ssml_parts.append(escaped_text)
            ssml_parts.append('</prosody>')
        else:
            ssml_parts.append(escaped_text)
            
        ssml_parts.append('</mstts:express-as>')
        ssml_parts.append('</voice>')
        ssml_parts.append('</speak>')
        
        clean_ssml = "".join(ssml_parts)
        
        debug_info["is_ssml"] = True
        debug_info["raw_ssml"] = clean_ssml
        
        communicate = edge_tts.Communicate(clean_ssml, voice)

    audio_data = io.BytesIO()
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data.write(chunk["data"])
    
    final_bytes = audio_data.getvalue()
    if remove_silence:
        final_bytes = trim_silence(final_bytes)
        
    return final_bytes, debug_info

# --- 6. ä»‹é¢é‚è¼¯ ---
def main():
    with st.sidebar:
        st.title("âš™ï¸ åƒæ•¸è¨­å®š")
        st.caption("ç‰ˆæœ¬ï¼šv10.1 (èªæ³•ä¿®å¾©ç‰ˆ)")
        
        if HAS_PYDUB and HAS_FFMPEG:
            st.markdown('<div class="status-ok">âœ… ç’°å¢ƒå®Œæ•´</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="status-err">âš ï¸ ç’°å¢ƒç¼ºå¤± (éœ€ Python 3.11)</div>', unsafe_allow_html=True)

        st.subheader("1. èªéŸ³")
        category = st.selectbox("èªè¨€", list(VOICES.keys()))
        selected_voice = st.selectbox("è§’è‰²", list(VOICES[category].keys()), format_func=lambda x: VOICES[category][x])

        st.subheader("2. èª¿æ•´")
        rate = st.slider("èªé€Ÿ", -50, 100, 0, format="%d%%")
        pitch = st.slider("éŸ³èª¿", -50, 50, 0, format="%dHz")
        rate_str = f"{'+' if rate >= 0 else ''}{rate}%"
        pitch_str = f"{'+' if pitch >= 0 else ''}{pitch}Hz"
        vol_str = "+0%"

        st.subheader("3. é¢¨æ ¼")
        if selected_voice in VOICES_WITH_STYLE:
            style = st.selectbox("æƒ…æ„Ÿ", list(STYLES.keys()), format_func=lambda x: STYLES[x], index=1)
        else:
            style = "general"
            st.selectbox("æƒ…æ„Ÿ", ["é è¨­ (General)"], disabled=True)

        remove_silence_opt = st.checkbox("âœ¨ è‡ªå‹•å»éœéŸ³", value=True, disabled=not(HAS_PYDUB and HAS_FFMPEG))
        show_debug = st.checkbox("ğŸ” é–‹å•Ÿ SSML æª¢è¦–", value=True)

    st.title("ğŸ§© æ ¼è‚² - å…’ç«¥èªéŸ³å·¥å…·")
    
    col1, col2 = st.columns([2, 1])
    with col1:
        text_input = st.text_area("è¼¸å…¥å…§å®¹", height=300, placeholder="001 è˜‹æœ\n002 é¦™è•‰")
    
    with col2:
        st.write("è©¦è½å€")
        test_txt = st.text_input("æ¸¬è©¦å¥", "å°æœ‹å‹å¥½ï¼")
        if st.button("ç”Ÿæˆè©¦è½"):
            with st.spinner("ç”Ÿæˆä¸­..."):
                try:
                    data, dbg = asyncio.run(generate_audio_stream(test_txt, selected_voice, rate_str, vol_str, pitch_str, style, remove_silence_opt))
                    st.audio(data, format='audio/mp3')
                    if show_debug and dbg.get("is_ssml"):
                         st.code(dbg["raw_ssml"], language="xml")
                except Exception as e:
                    st.error(f"éŒ¯èª¤: {e}")

    items = []
    for line in text_input.split('\n'):
        if line.strip():
            parts = line.strip().split(maxsplit=1)
            if len(parts) == 2:
                items.append((parts[0], parts[1]))
    
    if st.button(f"ğŸš€ æ‰¹é‡ç”Ÿæˆ ({len(items)} å€‹æª”æ¡ˆ)", type="primary", disabled=len(items)==0):
        zip_buffer = io.BytesIO()
        prog = st.progress(0)
        
        debug_container = st.expander("ğŸ” æ‰¹é‡ç”Ÿæˆ SSML æª¢æŸ¥", expanded=show_debug)
        
        # v10.1 ä¿®å¾©ï¼šåŠ ä¸Šäº† with èªå¥çµå°¾çš„å†’è™Ÿ :
        with zipfile.ZipFile(zip_buffer, "w") as zf:
            for i, (fname, txt) in enumerate(items):
                try:
                    data, dbg = asyncio.run(generate_audio_stream(txt, selected_voice, rate_str, vol_str, pitch_str, style, remove_silence_opt))
                    zf.writestr(f"{fname}.mp3", data)
                    
                    if show_debug and dbg.get("is_ssml") and i == 0:
                        with debug_container:
                            st.write(f"ğŸ“ ç¯„ä¾‹æª”æ¡ˆ: {fname}")
                            st.code(dbg["raw_ssml"], language="xml")
                            
                except Exception as e:
                    st.error(f"{fname} å¤±æ•—: {e}")
                prog.progress((i+1)/len(items))
        st.success("å®Œæˆï¼")
        st.download_button("ğŸ“¥ ä¸‹è¼‰ ZIP", zip_buffer.getvalue(), "audio.zip", "application/zip")

if __name__ == "__main__":
    main()