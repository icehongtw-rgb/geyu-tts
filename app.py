import streamlit as st
import edge_tts
import asyncio
import zipfile
import io
import shutil
import sys

# --- 1. ç’°å¢ƒæª¢æ¸¬ ---
HAS_FFMPEG = False
HAS_PYDUB = False

if shutil.which("ffmpeg"):
    HAS_FFMPEG = True

try:
    from pydub import AudioSegment
    HAS_PYDUB = True
except ImportError:
    HAS_PYDUB = False

# --- 2. è¨­å®šé é¢ ---
st.set_page_config(page_title="æ ¼è‚² - å…’ç«¥èªéŸ³å·¥å…·", page_icon="ğŸ§©", layout="wide")

# Minimalist Monochrome CSS
st.markdown("""
    <style>
    /* Global Background & Font */
    .stApp { 
        background-color: #ffffff; 
        color: #18181b;
    }
    
    /* Buttons - Override Primary to Black */
    div.stButton > button:first-child {
        background-color: #18181b;
        color: white;
        border-radius: 8px;
        border: none;
        padding: 0.75rem 1.5rem;
        font-weight: 600;
        transition: all 0.2s;
    }
    div.stButton > button:first-child:hover {
        background-color: #000000;
        color: white;
        border: none;
        transform: translateY(-1px);
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    }
    div.stButton > button:first-child:focus {
        border: none;
        outline: none;
        box-shadow: none;
    }

    /* Status Boxes - Monochrome */
    .status-ok { 
        background-color: #f4f4f5; 
        color: #52525b; 
        padding: 0.75rem; 
        border-radius: 8px; 
        margin-bottom: 15px; 
        border: 1px solid #e4e4e7;
        font-size: 0.9rem;
        display: flex;
        align-items: center;
        gap: 8px;
    }
    .status-err { 
        background-color: #f4f4f5; 
        color: #52525b; 
        padding: 0.75rem; 
        border-radius: 8px; 
        margin-bottom: 15px; 
        border: 1px solid #e4e4e7; /* Neutral border for error too in minimalist design, relying on text */
        font-size: 0.9rem;
    }
    
    /* Text Area */
    .stTextArea textarea { 
        min-height: 450px; 
        border-radius: 12px;
        border: 1px solid #e4e4e7;
        background-color: #fafafa;
        font-family: monospace;
    }
    .stTextArea textarea:focus {
        border-color: #18181b;
        box-shadow: 0 0 0 1px #18181b;
    }

    /* Sidebar */
    [data-testid="stSidebar"] {
        background-color: #fafafa;
        border-right: 1px solid #f4f4f5;
    }
    
    /* Headers */
    h1, h2, h3 {
        font-family: 'Inter', sans-serif;
        color: #18181b;
        font-weight: 700;
    }
    </style>
""", unsafe_allow_html=True)

# --- 3. æ•¸æ“šå®šç¾© (å·²é‡æ–°æ’åºï¼šå¥³è²åœ¨å‰ï¼Œç”·è²åœ¨å¾Œ) ---
VOICES = {
    "ç°¡é«”ä¸­æ–‡ (ä¸­åœ‹)": {
        "zh-CN-XiaoxiaoNeural": "ğŸ‡¨ğŸ‡³ å°æ›‰ (å¥³è² - æ´»æ½‘/æ¨è–¦) ğŸ”¥",
        "zh-CN-XiaoyiNeural": "ğŸ‡¨ğŸ‡³ å°è— (å¥³è² - æ°£è³ª)",
        "zh-CN-XiaohanNeural": "ğŸ‡¨ğŸ‡³ æ›‰æ¶µ (å¥³è² - æº«æš–)",
        "zh-CN-YunxiNeural": "ğŸ‡¨ğŸ‡³ é›²å¸Œ (ç”·è² - å¸¥æ°£)",
        "zh-CN-YunjianNeural": "ğŸ‡¨ğŸ‡³ é›²å¥ (ç”·è² - é«”è‚²)",
    },
    "ç¹é«”ä¸­æ–‡ (å°ç£)": {
        "zh-TW-HsiaoChenNeural": "ğŸ‡¹ğŸ‡¼ æ›‰è‡» (å¥³è² - æº«æŸ”/æ¨™æº–)",
        "zh-TW-HsiaoYuNeural": "ğŸ‡¹ğŸ‡¼ æ›‰é›¨ (å¥³è² - æ¸…æ™°)",
        "zh-TW-YunJheNeural": "ğŸ‡¹ğŸ‡¼ é›²å“² (ç”·è² - æ²‰ç©©)",
    },
    "è‹±æ–‡ (ç¾åœ‹)": {
        "en-US-AnaNeural": "ğŸ‡ºğŸ‡¸ Ana (å¥³è² - å…’ç«¥/å¯æ„›)",
        "en-US-AriaNeural": "ğŸ‡ºğŸ‡¸ Aria (å¥³è² - æ¨™æº–)",
        "en-US-GuyNeural": "ğŸ‡ºğŸ‡¸ Guy (ç”·è² - æ¨™æº–)",
    }
}

# é¢¨æ ¼é è¨­åƒæ•¸åº« (ç‰©ç†æ¨¡æ“¬æ³•)
STYLE_PRESETS = {
    "general":      {"rate": 0,   "pitch": 0},
    "affectionate": {"rate": -25, "pitch": -5}, # å“„å­©å­
    "cheerful":     {"rate": 15,  "pitch": 5},  # é–‹å¿ƒ
    "gentle":       {"rate": -10, "pitch": -2}, # æº«å’Œ
    "sad":          {"rate": -30, "pitch": -8}, # æ‚²å‚·
    "angry":        {"rate": 10,  "pitch": 8},  # ç”Ÿæ°£
    "whispering":   {"rate": -30, "pitch": -10},# è€³èª
    "shouting":     {"rate": 10,  "pitch": 12}, # å¤§å–Š
}

STYLES = {
    "general": "é è¨­ (General)",
    "affectionate": "â¤ï¸ è¦ªåˆ‡/å“„å­©å­",
    "cheerful": "ğŸ˜„ é–‹å¿ƒ",
    "gentle": "â˜ï¸ æº«å’Œ",
    "sad": "ğŸ˜¢ æ‚²å‚·",
    "angry": "ğŸ˜¡ ç”Ÿæ°£",
    "whispering": "ğŸ¤« è€³èª",
    "shouting": "ğŸ“¢ å¤§å–Š",
}

# --- 4. Session State åˆå§‹åŒ– ---
if 'rate_val' not in st.session_state:
    st.session_state['rate_val'] = 0
if 'pitch_val' not in st.session_state:
    st.session_state['pitch_val'] = 0

def update_sliders():
    selected_style = st.session_state.style_selection
    if selected_style in STYLE_PRESETS:
        st.session_state.rate_val = STYLE_PRESETS[selected_style]["rate"]
        st.session_state.pitch_val = STYLE_PRESETS[selected_style]["pitch"]

# --- 5. è¼”åŠ©åŠŸèƒ½ ---
def trim_silence(audio_bytes):
    if not HAS_PYDUB or not HAS_FFMPEG: return audio_bytes 
    try:
        audio = AudioSegment.from_file(io.BytesIO(audio_bytes), format="mp3")
        def detect_leading(sound, silence_threshold=-50.0, chunk_size=10):
            trim_ms = 0
            while trim_ms < len(sound) and sound[trim_ms:trim_ms+chunk_size].dBFS < silence_threshold:
                trim_ms += chunk_size
            return trim_ms
        start_trim = detect_leading(audio)
        end_trim = detect_leading(audio.reverse())
        if start_trim + end_trim < len(audio):
            trimmed = audio[start_trim:len(audio)-end_trim]
            out = io.BytesIO()
            trimmed.export(out, format="mp3")
            return out.getvalue()
    except: pass 
    return audio_bytes

# --- 6. æ ¸å¿ƒç”Ÿæˆé‚è¼¯ (ç´”åƒæ•¸ç‰ˆ) ---
async def generate_audio_stream(text, voice, rate_val, volume_val, pitch_val, remove_silence=False):
    rate_str = f"{rate_val:+d}%"
    pitch_str = f"{pitch_val:+d}Hz"
    volume_str = f"{volume_val:+d}%"
    
    communicate = edge_tts.Communicate(
        text, 
        voice, 
        rate=rate_str, 
        volume=volume_str, 
        pitch=pitch_str
    )

    audio_data = io.BytesIO()
    async for chunk in communicate.stream():
        if chunk["type"] == "audio":
            audio_data.write(chunk["data"])
    
    final_bytes = audio_data.getvalue()
    
    if remove_silence:
        final_bytes = trim_silence(final_bytes)
        
    return final_bytes

# --- 7. ä»‹é¢é‚è¼¯ ---
def main():
    with st.sidebar:
        st.title("åƒæ•¸è¨­å®š")
        st.caption("Version 19.0 / Monochrome")
        
        if HAS_PYDUB and HAS_FFMPEG:
            st.markdown('<div class="status-ok"><span>â—</span> Python ç’°å¢ƒå®Œæ•´</div>', unsafe_allow_html=True)
        else:
            st.markdown('<div class="status-err"><span>â—‹</span> ç’°å¢ƒç¼ºå¤± (éœ€ ffmpeg)</div>', unsafe_allow_html=True)

        st.markdown("### 1. èªéŸ³")
        category = st.selectbox("èªè¨€å€åŸŸ", list(VOICES.keys()))
        selected_voice = st.selectbox("è§’è‰²é¸æ“‡", list(VOICES[category].keys()), format_func=lambda x: VOICES[category][x])

        st.markdown("### 2. é¢¨æ ¼ (ç‰©ç†æ¨¡æ“¬)")
        st.selectbox(
            "æƒ…æ„Ÿé è¨­", 
            list(STYLES.keys()), 
            format_func=lambda x: STYLES[x], 
            index=0,
            key="style_selection",
            on_change=update_sliders
        )
        st.caption("é€éèª¿æ•´èªé€Ÿèˆ‡éŸ³èª¿æ¨¡æ“¬æƒ…æ„Ÿï¼Œé©ç”¨æ‰€æœ‰è§’è‰²ã€‚")

        st.markdown("### 3. å¾®èª¿")
        rate = st.slider("èªé€Ÿ (Rate)", -100, 100, key="rate_val", format="%d%%")
        pitch = st.slider("éŸ³èª¿ (Pitch)", -100, 100, key="pitch_val", format="%dHz")
        volume = st.slider("éŸ³é‡ (Volume)", -100, 100, 0, format="%d%%")

        st.markdown("---")
        remove_silence_opt = st.checkbox("æ™ºèƒ½å»éœéŸ³", value=True, disabled=not(HAS_PYDUB and HAS_FFMPEG))

    st.title("å…’ç«¥èªéŸ³åˆæˆå·¥å…·")
    st.markdown("å°ˆç‚ºæ•™æè£½ä½œè¨­è¨ˆçš„æ‰¹é‡ç”Ÿæˆå¼•æ“ã€‚")
    
    text_input = st.text_area("è¼¸å…¥å…§å®¹ (ç·¨è™Ÿ å…§å®¹)", height=450, placeholder="001 è˜‹æœ\n002 é¦™è•‰\n\n(è‹¥æœªè¼¸å…¥ç·¨è™Ÿï¼Œç³»çµ±å°‡è‡ªå‹•ç”¢ç”Ÿ)")
    
    items = []
    lines = text_input.split('\n')
    for i, line in enumerate(lines):
        if line.strip():
            # Robust parsing:
            parts = line.strip().split(maxsplit=1)
            if len(parts) >= 2:
                items.append((parts[0], parts[1]))
            elif len(parts) == 1:
                auto_id = f"auto_{i+1:03d}"
                items.append((auto_id, parts[0]))
    
    # ä½¿ç”¨ç©ºç™½å°‡æŒ‰éˆ•æ¨åˆ°åº•éƒ¨æˆ–å¢åŠ é–“è·
    st.markdown("<br>", unsafe_allow_html=True)
    
    if st.button(f"é–‹å§‹æ‰¹é‡ç”Ÿæˆ ({len(items)} æª”æ¡ˆ)", type="primary", disabled=len(items)==0):
        zip_buffer = io.BytesIO()
        prog = st.progress(0)
        
        with zipfile.ZipFile(zip_buffer, "w") as zf:
            for i, (fname, txt) in enumerate(items):
                try:
                    data = asyncio.run(generate_audio_stream(txt, selected_voice, rate, volume, pitch, remove_silence_opt))
                    zf.writestr(f"{fname}.mp3", data)
                except Exception as e:
                    st.error(f"{fname} å¤±æ•—: {e}")
                prog.progress((i+1)/len(items))
        st.success("ç”Ÿæˆå®Œæˆï¼")
        st.download_button("ä¸‹è¼‰ ZIP å£“ç¸®æª”", zip_buffer.getvalue(), "audio.zip", "application/zip")

if __name__ == "__main__":
    main()